{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775bc45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rahat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from nltk import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20d0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('baby_products_key_data_2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a51663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>tokenized_review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['loved', 'swaddle', 'blankets', 'daughter', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['these', 'adorable', 'pacifier', 'clips', 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['great', 'gift']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['these', 'forks', 'great', 'month', 'old', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['i', 'wanted', 'something', 'piece', 'mind', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748943</th>\n",
       "      <td>1749143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['my', 'month', 'old', 'son', 'loves', 'play',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748944</th>\n",
       "      <td>1749144</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['not', 'son', 'love', 'toy', 'the', 'base', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748945</th>\n",
       "      <td>1749145</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['this', 'toy', 'offers', 'fun', 'learning', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748946</th>\n",
       "      <td>1749146</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['our', 'fun', 'soon', 'got', 'it', 'continues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748947</th>\n",
       "      <td>1749147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['the', 'hourglass', 'rattle', 'sassy', 'defin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1748948 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  star_rating  \\\n",
       "0                 0          5.0   \n",
       "1                 1          5.0   \n",
       "2                 2          5.0   \n",
       "3                 3          5.0   \n",
       "4                 4          5.0   \n",
       "...             ...          ...   \n",
       "1748943     1749143          5.0   \n",
       "1748944     1749144          5.0   \n",
       "1748945     1749145          5.0   \n",
       "1748946     1749146          5.0   \n",
       "1748947     1749147          5.0   \n",
       "\n",
       "                                     tokenized_review_body  \n",
       "0        ['loved', 'swaddle', 'blankets', 'daughter', '...  \n",
       "1        ['these', 'adorable', 'pacifier', 'clips', 'sa...  \n",
       "2                                        ['great', 'gift']  \n",
       "3        ['these', 'forks', 'great', 'month', 'old', 'd...  \n",
       "4        ['i', 'wanted', 'something', 'piece', 'mind', ...  \n",
       "...                                                    ...  \n",
       "1748943  ['my', 'month', 'old', 'son', 'loves', 'play',...  \n",
       "1748944  ['not', 'son', 'love', 'toy', 'the', 'base', '...  \n",
       "1748945  ['this', 'toy', 'offers', 'fun', 'learning', '...  \n",
       "1748946  ['our', 'fun', 'soon', 'got', 'it', 'continues...  \n",
       "1748947  ['the', 'hourglass', 'rattle', 'sassy', 'defin...  \n",
       "\n",
       "[1748948 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76067d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tokenized_review_body']\n",
    "y = data['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa31f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model):\n",
    "    word_seq = np.array(\n",
    "        [\n",
    "            vocab[preprocess_string(word)]\n",
    "            for word in text.split()\n",
    "            if preprocess_string(word) in vocab.keys()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    word_seq = np.expand_dims(word_seq, axis=0)\n",
    "\n",
    "    pad = torch.from_numpy(padding_(word_seq, 500))\n",
    "\n",
    "    inputs = pad.to(device)\n",
    "\n",
    "    batch_size = 1\n",
    "\n",
    "    h = model.init_hidden(batch_size)\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    output, h = model(inputs, h)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93889475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters).\n",
    "\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "\n",
    "    # Replace all runs of whitespaces with no space.\n",
    "\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "\n",
    "    # Replace digits with no space.\n",
    "\n",
    "    s = re.sub(r\"\\d\", \"\", s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c992803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "826eb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(X_train, y_train, x_val, y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    for sent in X_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != \"\":\n",
    "                word_list.append(word)\n",
    "\n",
    "    # corpus: A collection of words.\n",
    "\n",
    "    corpus = Counter(word_list)\n",
    "\n",
    "    # Sorting on the basis of most common words.\n",
    "\n",
    "    corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:1000]\n",
    "\n",
    "    # Create a dictionary.\n",
    "\n",
    "    onehot_dict = {w: i + 1 for i, w in enumerate(corpus_)}\n",
    "\n",
    "    # Tokenize.\n",
    "\n",
    "    final_list_train, final_list_test = [], []\n",
    "\n",
    "    for sent in X_train:\n",
    "        final_list_train.append(\n",
    "            [\n",
    "                onehot_dict[preprocess_string(word)]\n",
    "                for word in sent.lower().split()\n",
    "                if preprocess_string(word) in onehot_dict.keys()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for sent in x_val:\n",
    "        final_list_test.append(\n",
    "            [\n",
    "                onehot_dict[preprocess_string(word)]\n",
    "                for word in sent.lower().split()\n",
    "                if preprocess_string(word) in onehot_dict.keys()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    encoded_train = [1 if label == \"positive\" else 0 for label in y_train]\n",
    "\n",
    "    encoded_test = [1 if label == \"positive\" else 0 for label in y_val]\n",
    "\n",
    "    return (\n",
    "        np.array(final_list_train, dtype=object),\n",
    "        np.array(encoded_train),\n",
    "        np.array(final_list_test, dtype=object),\n",
    "        np.array(encoded_test),\n",
    "        onehot_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67f1de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, vocab = tokenize(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b129c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = 'great'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112270ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/1741228796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgood_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/1922209177.py\u001b[0m in \u001b[0;36mpredict_text\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     word_seq = np.array(\n\u001b[1;32m----> 3\u001b[1;33m         [\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreprocess_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/1922209177.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreprocess_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mpreprocess_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         ]\n\u001b[0;32m      8\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "test = predict_text(good_words, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db6078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
